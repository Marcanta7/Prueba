{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copia del bueno por si nos rallamos y hay que cambiar algo mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.runners import DataflowRunner\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import apache_beam.transforms.window as window\n",
    "from apache_beam.metrics import Metrics\n",
    "from apache_beam.io.gcp.bigquery import WriteToBigQuery\n",
    "from apache_beam.io.gcp.bigquery import BigQueryDisposition\n",
    "\n",
    "# B. Apache Beam ML Libraries\n",
    "from apache_beam.ml.inference.base import ModelHandler\n",
    "from apache_beam.ml.inference.base import RunInference\n",
    "\n",
    "# C. Python Libraries\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "def ParsePubSubMessages(message): \n",
    "    pubsub_message= message.decode('utf-8')\n",
    "\n",
    "    msg = json.loads(pubsub_message)\n",
    "\n",
    "    #logging.info(\"New message: %s\", msg)\n",
    "\n",
    "    return msg\n",
    "\n",
    "def add_type(record, msg_type):\n",
    "    \"\"\"\n",
    "    Asigna el campo \"type\" con el valor \"affected\" o \"volunteer\"\n",
    "    para diferenciar el origen del mensaje.\n",
    "    \"\"\"\n",
    "    record['type'] = msg_type\n",
    "    return record\n",
    "\n",
    "def increment_processed(record):\n",
    "    \"\"\"\n",
    "    Incremente el campo 'processed'. Por defecto estará en 0,\n",
    "    y cada vez que se lee el mensaje del Pub/Sub, se aumenta en 1.\n",
    "    \"\"\"\n",
    "    record['processed'] = record.get('processed', 0) + 1\n",
    "    return record\n",
    "\n",
    "def key_by_match_fields(record):\n",
    "    \"\"\"\n",
    "    Returns a tuple: (\n",
    "        (city, necessity, disponibility),\n",
    "        record\n",
    "    )\n",
    "    \"\"\"\n",
    "    return (\n",
    "        (record[\"city\"], record[\"necessity\"], record[\"disponibility\"]), \n",
    "        record\n",
    "    )\n",
    "\n",
    "def produce_matches(element):\n",
    "    \"\"\"\n",
    "    Receives something like:\n",
    "        element = ( key, { 'affected': [...], 'volunteer': [...] } )\n",
    "    and we produce:\n",
    "        - All matched (afectado, voluntario) pairs\n",
    "        - All affected with NO volunteer\n",
    "        - All volunteer with NO affected\n",
    "    \"\"\"\n",
    "    key, grouped = element\n",
    "    afectados = grouped['affected']\n",
    "    voluntarios = grouped['volunteer']\n",
    "\n",
    "\n",
    "    for afectado in afectados:\n",
    "        found_any = False\n",
    "        for voluntario in voluntarios:\n",
    "            found_any = True\n",
    "            yield beam.pvalue.TaggedOutput(\n",
    "                'matched',\n",
    "                {\n",
    "                    'afectado': afectado,\n",
    "                    'voluntario': voluntario\n",
    "                }\n",
    "            )\n",
    "        if not found_any:\n",
    "            # This afectado had zero volunteers\n",
    "            yield beam.pvalue.TaggedOutput(\n",
    "                'non_matched_affected',\n",
    "                afectado\n",
    "            )\n",
    "\n",
    "    if not afectados:\n",
    "\n",
    "        for voluntario in voluntarios:\n",
    "            yield beam.pvalue.TaggedOutput('non_matched_volunteer', voluntario)\n",
    "\n",
    "def format_matched_for_bq(record):\n",
    "    \"\"\"\n",
    "    Del match, solo se pide:\n",
    "      - city, necessity, disponibility\n",
    "      - nombre y teléfono del afectado\n",
    "      - nombre y teléfono del voluntario\n",
    "    \"\"\"\n",
    "    afectado = record['afectado']\n",
    "    voluntario = record['voluntario']\n",
    "\n",
    "    return {\n",
    "        \"city\": afectado.get(\"city\", \"\"),\n",
    "        \"necessity\": afectado.get(\"necessity\", \"\"),\n",
    "        \"disponibility\": afectado.get(\"disponibility\", \"\"),\n",
    "        \"affected_name\": afectado.get(\"name\", \"\"),\n",
    "        \"affected_phone\": afectado.get(\"phone\", \"\"),\n",
    "        \"volunteer_name\": voluntario.get(\"name\", \"\"),\n",
    "        \"volunteer_phone\": voluntario.get(\"phone\", \"\")\n",
    "    }\n",
    "\n",
    "def format_unmatched_for_bq(record):\n",
    "    \"\"\"\n",
    "        Para los no matcheados (cuando 'processed' >= 7), se desea una fila con:\n",
    "         type, timestamp, name, phone, category, message,\n",
    "        necessity, city, disponibility, processed\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        \"type\": record.get(\"type\", \"\"),\n",
    "        \"timestamp\": record.get(\"timestamp\", \"\"),\n",
    "        \"name\": record.get(\"name\", \"\"),\n",
    "        \"phone\": record.get(\"phone\", \"\"),\n",
    "        \"category\": record.get(\"category\", \"\"),\n",
    "        \"message\": record.get(\"message\", \"\"),\n",
    "        \"necessity\": record.get(\"necessity\", \"\"),\n",
    "        \"city\": record.get(\"city\", \"\"),\n",
    "        \"disponibility\": record.get(\"disponibility\", \"\"),\n",
    "        \"processed\": record.get(\"processed\", 0)\n",
    "    }\n",
    "\n",
    "def run():\n",
    "    parser = argparse.ArgumentParser(description=('Input arguments for the Dataflow Streaming Pipeline.'))\n",
    "\n",
    "    parser.add_argument(\n",
    "                '--project_id',\n",
    "                required=True,\n",
    "                help='GCP cloud project name, in this case data-project-2425')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--affected_sub',\n",
    "                required=True,\n",
    "                help='PubSub sub used for reading affected people. In this case the subscripcion will be: affected-sub')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--volunteer_sub',\n",
    "                required=True,\n",
    "                help='PubSub sub used for reading volunteer prople. In this case the subscripcion will be: volunteer-sub')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--volunteer_topic',\n",
    "                required=True,\n",
    "                help='PubSub Topic for storing data that has been processed and not matched. In this case the value will be: volunteer')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--affected_topic',\n",
    "                required=True,\n",
    "                help='PubSub Topic for storing data that has been processed and not matched. In this case the value will be: affected')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--bq_dataset',\n",
    "                required=True, \n",
    "                help='Name of the BigQuery.')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--matched_table', \n",
    "                    default='matched', \n",
    "                    help='Name for the table of matches messages.')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--unmatched_table', \n",
    "                default='unmatched',  \n",
    "                help='Name for the table of non-matches messages.')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--temp_location', \n",
    "                required=True,\n",
    "                help= 'this will be: gs://dataflow_bucket_dataproject_2425/tmp')\n",
    "    \n",
    "    parser.add_argument(\n",
    "                '--staging_location', \n",
    "                required=True,\n",
    "                help='This will be: gs://dataflow_bucket_dataproject_2425/stg')\n",
    "    \n",
    "    \n",
    "    args, pipeline_opts = parser.parse_known_args()\n",
    "\n",
    "    options = PipelineOptions(pipeline_opts, \n",
    "        save_main_session= True, streaming= True, project= args.project_id)\n",
    "    \n",
    "    \n",
    "    # Definimos los nombres completos de las tablas BQ (proyecto:dataset.tabla)\n",
    "    matched_table_id = f\"{args.project_id}:{args.bq_dataset}.{args.matched_table}\"\n",
    "    unmatched_table_id = f\"{args.project_id}:{args.bq_dataset}.{args.unmatched_table}\"\n",
    "\n",
    "    # Definición de los esquemas de las tablas\n",
    "    matched_schema = {\n",
    "        \"fields\": [\n",
    "            {\"name\": \"city\",            \"type\": \"STRING\", \"mode\": \"REQUIRED\"},\n",
    "            {\"name\": \"necessity\",       \"type\": \"STRING\", \"mode\": \"REQUIRED\"},\n",
    "            {\"name\": \"disponibility\",   \"type\": \"STRING\", \"mode\": \"REQUIRED\"},\n",
    "            {\"name\": \"affected_name\",   \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"affected_phone\",  \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"volunteer_name\",  \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"volunteer_phone\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    unmatched_schema = {\n",
    "        \"fields\": [\n",
    "            {\"name\": \"type\",           \"type\": \"STRING\",  \"mode\": \"REQUIRED\"}, \n",
    "            {\"name\": \"timestamp\",      \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"name\",           \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"phone\",          \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"category\",       \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"message\",        \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"necessity\",      \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"city\",           \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"disponibility\",  \"type\": \"STRING\",  \"mode\": \"NULLABLE\"},\n",
    "            {\"name\": \"processed\",      \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with beam.Pipeline(options=options) as p:\n",
    "\n",
    "        # 1) Lectura de Afectados: parsear JSON, setear type=affected, incrementar processed, agrupar\n",
    "        affected_data = (\n",
    "            p\n",
    "            | \"ReadAffected\" >> beam.io.ReadFromPubSub(subscription=args.affected_sub)\n",
    "            | \"ParseAffected\" >> beam.Map(ParsePubSubMessages)\n",
    "            | \"MarkTypeAffected\" >> beam.Map(add_type, \"affected\")\n",
    "            | \"IncrementProcessedAffected\" >> beam.Map(increment_processed)\n",
    "            | \"WindowAffected\" >> beam.WindowInto(window.FixedWindows(60))\n",
    "            | \"KeyAffected\" >> beam.Map(key_by_match_fields)\n",
    "        )\n",
    "\n",
    "        # 2) Lectura de Voluntarios: parsear JSON, setear type=volunteer, incrementar processed, agrupar\n",
    "        volunteer_data = (\n",
    "            p\n",
    "            | \"ReadVolunteers\" >> beam.io.ReadFromPubSub(subscription=args.volunteer_sub)\n",
    "            | \"ParseVolunteers\" >> beam.Map(ParsePubSubMessages)\n",
    "            | \"MarkTypeVolunteer\" >> beam.Map(add_type, \"volunteer\")\n",
    "            | \"IncrementProcessedVolunteer\" >> beam.Map(increment_processed)\n",
    "            | \"WindowVolunteers\" >> beam.WindowInto(window.FixedWindows(60))\n",
    "            | \"KeyVolunteers\" >> beam.Map(key_by_match_fields)\n",
    "        )\n",
    "\n",
    "        # 3) CoGroupByKey para emparejar (city, necessity, disponibility)\n",
    "        grouped = (\n",
    "            {\n",
    "                'affected': affected_data,\n",
    "                'volunteer': volunteer_data\n",
    "            }\n",
    "            | \"CoGroupByKey\" >> beam.CoGroupByKey()\n",
    "        )\n",
    "\n",
    "        # 4) produce_matches genera 3 salidas: matched, non_matched_affected, non_matched_volunteer\n",
    "        results = (\n",
    "            grouped\n",
    "            | \"ProduceMatches\" >> beam.ParDo(produce_matches)\n",
    "              .with_outputs('matched', 'non_matched_affected', 'non_matched_volunteer')\n",
    "        )\n",
    "\n",
    "        matched_pcoll = results['matched']\n",
    "        unmatched_affected_pcoll = results['non_matched_affected']\n",
    "        unmatched_volunteer_pcoll = results['non_matched_volunteer']\n",
    "\n",
    "        # 5) Manejo de 'matched': se escribe directamente a la tabla BQ matcheada\n",
    "        (\n",
    "            matched_pcoll\n",
    "            | \"FormatMatchedForBQ\" >> beam.Map(format_matched_for_bq)\n",
    "            | \"WriteMatchedToBQ\" >> WriteToBigQuery(\n",
    "                table=matched_table_id,\n",
    "                schema=matched_schema,\n",
    "                create_disposition=BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                write_disposition=BigQueryDisposition.WRITE_APPEND\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 6) Manejo de NO matcheados:\n",
    "        #    - Si processed < 7 => re-publicar a su tópico original\n",
    "        #    - Si processed >= 7 => escribir a BQ \"unmatched\" con la estructura deseada\n",
    "\n",
    "        # A) Afectados no matcheados\n",
    "        unmatched_affected_less_7 = unmatched_affected_pcoll | \"FilterAff<7\" >> beam.Filter(lambda x: x.get('processed', 0) < 7)\n",
    "        unmatched_affected_ge_7   = unmatched_affected_pcoll | \"FilterAff>=7\" >> beam.Filter(lambda x: x.get('processed', 0) >= 7)\n",
    "\n",
    "        # B) Voluntarios no matcheados\n",
    "        unmatched_volunteer_less_7 = unmatched_volunteer_pcoll | \"FilterVol<7\" >> beam.Filter(lambda x: x.get('processed', 0) < 7)\n",
    "        unmatched_volunteer_ge_7   = unmatched_volunteer_pcoll | \"FilterVol>=7\" >> beam.Filter(lambda x: x.get('processed', 0) >= 7)\n",
    "\n",
    "        # Re-publicar los que tienen processed < 7 al tópico original\n",
    "        (\n",
    "            unmatched_affected_less_7\n",
    "            | \"ReEncodeAff<7\" >> beam.Map(lambda x: json.dumps(x).encode('utf-8'))\n",
    "            | \"RePublishAff<7\" >> beam.io.WriteToPubSub(topic=args.affected_topic)\n",
    "        )\n",
    "        (\n",
    "            unmatched_volunteer_less_7\n",
    "            | \"ReEncodeVol<7\" >> beam.Map(lambda x: json.dumps(x).encode('utf-8'))\n",
    "            | \"RePublishVol<7\" >> beam.io.WriteToPubSub(topic=args.volunteer_topic)\n",
    "        )\n",
    "\n",
    "        # Combinar todos los no matcheados >= 7 en un solo PCollection\n",
    "        unmatched_ge_7 = (\n",
    "            (unmatched_affected_ge_7, unmatched_volunteer_ge_7)\n",
    "            | \"FlattenUnmatched>=7\" >> beam.Flatten()\n",
    "        )\n",
    "\n",
    "        # Guardar en BQ con la estructura deseada\n",
    "        (\n",
    "            unmatched_ge_7\n",
    "            | \"FormatUnmatchedForBQ\" >> beam.Map(format_unmatched_for_bq)\n",
    "            | \"WriteUnmatchedToBQ\" >> WriteToBigQuery(\n",
    "                table=unmatched_table_id,\n",
    "                schema=unmatched_schema,\n",
    "                create_disposition=BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                write_disposition=BigQueryDisposition.WRITE_APPEND\n",
    "            )\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Set Logs\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    # Disable logs from apache_beam.utils.subprocess_server\n",
    "    logging.getLogger(\"apache_beam.utils.subprocess_server\").setLevel(logging.ERROR)\n",
    "\n",
    "    logging.info(\"The process started\")\n",
    "\n",
    "    # Run Process\n",
    "    run()\n",
    "\n",
    "    '''\n",
    "\n",
    "Till here i want to prove if the code is correct let's run it on dataflow  run pipeline in GCP: dataflow\n",
    "\n",
    "        python new_dataflow_pipeline.py \\\n",
    "    --project_id 'data-project-2425' \\\n",
    "    --affected_sub 'projects/data-project-2425/subscriptions/affected-sub' \\\n",
    "    --volunteer_sub 'projects/data-project-2425/subscriptions/volunteer-sub' \\\n",
    "    --volunteer_topic 'projects/data-project-2425/topics/volunteer' \\\n",
    "    --affected_topic 'projects/data-project-2425/topics/affected' \\\n",
    "    --bq_dataset 'terreta_data' \\\n",
    "    --matched_table 'matched_table' \\\n",
    "    --unmatched_table 'non_matched_table' \\\n",
    "    --system_id 'vvercherg' \\\n",
    "    --runner DataflowRunner \\\n",
    "    --job_name 'data-flow-pruebas-1234-dataflow' \\\n",
    "    --region 'europe-west1' \\\n",
    "    --temp_location 'gs://dataflow_bucket_dataproject_2425/tmp' \\\n",
    "    --staging_location 'gs://dataflow_bucket_dataproject_2425/stg' \\\n",
    "    --requirements_file 'requirements.txt'\n",
    "\n",
    "    \n",
    "correrlo de forma local\n",
    "\n",
    "    python new_dataflow_pipeline.py \\\n",
    "    --project_id 'data-project-2425' \\\n",
    "    --affected_sub 'projects/data-project-2425/subscriptions/affected-sub' \\\n",
    "    --volunteer_sub 'projects/data-project-2425/subscriptions/volunteer-sub' \\\n",
    "    --volunteer_topic 'projects/data-project-2425/topics/volunteer' \\\n",
    "    --affected_topic 'projects/data-project-2425/topics/affected' \\\n",
    "    --output_topic_non_matched 'projects/data-project-2425/topics/no-matched' \\\n",
    "    --output_topic_matched 'projects/data-project-2425/topics/matched' \n",
    "    \n",
    "\n",
    "\n",
    "    topics :\n",
    "\n",
    "    affected \n",
    "    volunteer\n",
    "    matched\n",
    "    no-matched \n",
    "    \n",
    "    de aqui sacamos en claro que lee los mensajes y que le hace la window de 90 segundos\n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
